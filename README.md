# PEIT
![image](https://github.com/user-attachments/assets/d9cd42da-f7e3-47b7-bb46-aabcc39ddc1b)
We have initially uploaded the PEIT-GEN pretraining code (PEIT_pretrain.py) along with the template generation code for various tasks in the Template_Generation module. Additionally, we have made part of the LLM instruction dataset publicly available at https://pan.baidu.com/s/1VcFvrVHmjBZpL2L_QWt9TQ?pwd=vvts. The PEIT-LLM-LLaMA-3.1-8B model has also been uploaded to Hugging Face (https://huggingface.co/ccsalong/PEIT-LLMs-LLaMA3.1-8B/tree/main). The remaining code will be fully released in the near future.
